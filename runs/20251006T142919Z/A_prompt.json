```json
{
  "bundle_manifest": [
    {
      "path": "infra/terraform/app.tf",
      "purpose": "Main overlay wiring all services: API Gateway, Lambdas, DynamoDB tables, EventBridge bus, S3 bucket, and integrations"
    },
    {
      "path": "infra/terraform/variables.tf",
      "purpose": "Project-level variables (project, env, region) and resource naming"
    },
    {
      "path": "infra/terraform/outputs.tf",
      "purpose": "Expose API endpoint, table names, bus name, bucket name for downstream use"
    },
    {
      "path": "infra/terraform/backend.tf",
      "purpose": "S3 backend configuration for remote state with DynamoDB locking"
    },
    {
      "path": "infra/terraform/iam.tf",
      "purpose": "Least-privilege IAM roles and policies for each Lambda function"
    },
    {
      "path": ".github/workflows/ci.yml",
      "purpose": "CI/CD pipeline: lint, test, package, terraform validate/plan, apply to staging on main via OIDC"
    },
    {
      "path": "src/orders/adapter.py",
      "purpose": "Thin adapter ensuring orders handlers conform to Lambda signature and env var access"
    },
    {
      "path": "src/inventory/adapter.py",
      "purpose": "Thin adapter for inventory reserve handler"
    },
    {
      "path": "src/ingestor/adapter.py",
      "purpose": "Thin adapter for CRM CSV ingestor"
    },
    {
      "path": "src/receipts/adapter.py",
      "purpose": "Thin adapter for receipts worker"
    },
    {
      "path": "src/ops/adapter.py",
      "purpose": "Thin adapter for health check handler"
    },
    {
      "path": "readme.md",
      "purpose": "Instructions for local dev, testing, deployment, and rollback"
    },
    {
      "path": "changelog.md",
      "purpose": "Inference log, assumptions, and TODOs"
    }
  ],
  "src": {
    "files": [
      {
        "path": "src/orders/adapter.py",
        "content": "# src/orders/adapter.py\n# Thin adapter to ensure handlers module is importable and env vars are set.\nimport sys\nimport os\n\n# Re-export handlers for Lambda runtime\nfrom .handlers import create_order, get_order\n\n__all__ = [\"create_order\", \"get_order\"]\n"
      },
      {
        "path": "src/inventory/adapter.py",
        "content": "# src/inventory/adapter.py\n# Thin adapter for inventory reserve handler.\nfrom .handlers import reserve\n\n__all__ = [\"reserve\"]\n"
      },
      {
        "path": "src/ingestor/adapter.py",
        "content": "# src/ingestor/adapter.py\n# Thin adapter for CRM CSV ingestor.\nfrom .process_csv import handler\n\n__all__ = [\"handler\"]\n"
      },
      {
        "path": "src/receipts/adapter.py",
        "content": "# src/receipts/adapter.py\n# Thin adapter for receipts worker.\nfrom .worker import handler\n\n__all__ = [\"handler\"]\n"
      },
      {
        "path": "src/ops/adapter.py",
        "content": "# src/ops/adapter.py\n# Thin adapter for health check.\nfrom .health import handler\n\n__all__ = [\"handler\"]\n"
      }
    ]
  },
  "infra": {
    "terraform": {
      "files": [
        {
          "path": "infra/terraform/backend.tf",
          "content": "# infra/terraform/backend.tf\n# S3 backend for remote state with DynamoDB locking.\nterraform {\n  backend \"s3\" {\n    bucket         = \"${var.project}-${var.env}-tfstate\"\n    key            = \"app/terraform.tfstate\"\n    region         = var.region\n    dynamodb_table = \"${var.project}-${var.env}-tflock\"\n    encrypt        = true\n  }\n}\n"
        },
        {
          "path": "infra/terraform/variables.tf",
          "content": "# infra/terraform/variables.tf\nvariable \"project\" {\n  type        = string\n  description = \"Project name for resource naming\"\n  default     = \"serverless-app\"\n}\n\nvariable \"env\" {\n  type        = string\n  description = \"Environment (staging, prod)\"\n  default     = \"staging\"\n}\n\nvariable \"region\" {\n  type        = string\n  description = \"AWS region\"\n  default     = \"us-east-1\"\n}\n\nvariable \"tags\" {\n  type        = map(string)\n  description = \"Common tags for all resources\"\n  default     = {}\n}\n\nlocals {\n  name_prefix = \"${var.project}-${var.env}\"\n  common_tags = merge(var.tags, {\n    Project     = var.project\n    Environment = var.env\n    ManagedBy   = \"Terraform\"\n  })\n}\n"
        },
        {
          "path": "infra/terraform/app.tf",
          "content": "# infra/terraform/app.tf\n# Main overlay wiring all services.\n\nterraform {\n  required_version = \">= 1.7.0\"\n  required_providers {\n    aws = { source = \"hashicorp/aws\", version = \">= 5.0\" }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n}\n\n# ========== EventBridge Bus ==========\nresource \"aws_cloudwatch_event_bus\" \"main\" {\n  name = \"${local.name_prefix}-bus\"\n  tags = local.common_tags\n}\n\n# ========== DynamoDB Tables ==========\n# Orders table\nresource \"aws_dynamodb_table\" \"orders\" {\n  name         = \"${local.name_prefix}-orders\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"order_id\"\n\n  attribute {\n    name = \"order_id\"\n    type = \"S\"\n  }\n\n  tags = local.common_tags\n}\n\n# Inventory table (includes idempotency markers with TTL)\nresource \"aws_dynamodb_table\" \"inventory\" {\n  name         = \"${local.name_prefix}-inventory\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"sku\"\n\n  attribute {\n    name = \"sku\"\n    type = \"S\"\n  }\n\n  ttl {\n    attribute_name = \"ttl\"\n    enabled        = true\n  }\n\n  tags = local.common_tags\n}\n\n# ========== S3 Bucket for CRM CSV ingestion ==========\nresource \"aws_s3_bucket\" \"crm_ingestion\" {\n  bucket        = \"${local.name_prefix}-crm-ingestion\"\n  force_destroy = true\n  tags          = local.common_tags\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"crm_block\" {\n  bucket                  = aws_s3_bucket.crm_ingestion.id\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\n# ========== HTTP API Gateway ==========\nresource \"aws_apigatewayv2_api\" \"http_api\" {\n  name          = \"${local.name_prefix}-api\"\n  protocol_type = \"HTTP\"\n\n  cors_configuration {\n    allow_headers = [\"*\"]\n    allow_methods = [\"*\"]\n    allow_origins = [\"*\"]\n  }\n\n  tags = local.common_tags\n}\n\nresource \"aws_apigatewayv2_stage\" \"default\" {\n  api_id      = aws_apigatewayv2_api.http_api.id\n  name        = \"$default\"\n  auto_deploy = true\n}\n\n# ========== Lambda Functions ==========\n# Package placeholder (CI will build deployment package)\ndata \"archive_file\" \"lambda_zip\" {\n  type        = \"zip\"\n  source_dir  = \"${path.module}/../../src\"\n  output_path = \"${path.module}/lambda_package.zip\"\n}\n\n# Orders: create_order\nresource \"aws_lambda_function\" \"orders_create\" {\n  function_name = \"${local.name_prefix}-orders-create\"\n  role          = aws_iam_role.orders_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"orders.handlers.create_order\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      ORDERS_TABLE    = aws_dynamodb_table.orders.name\n      EVENT_BUS_NAME  = aws_cloudwatch_event_bus.main.name\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# Orders: get_order\nresource \"aws_lambda_function\" \"orders_get\" {\n  function_name = \"${local.name_prefix}-orders-get\"\n  role          = aws_iam_role.orders_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"orders.handlers.get_order\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      ORDERS_TABLE = aws_dynamodb_table.orders.name\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# Inventory: reserve\nresource \"aws_lambda_function\" \"inventory_reserve\" {\n  function_name = \"${local.name_prefix}-inventory-reserve\"\n  role          = aws_iam_role.inventory_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"inventory.handlers.reserve\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      INVENTORY_TABLE = aws_dynamodb_table.inventory.name\n      EVENT_BUS_NAME  = aws_cloudwatch_event_bus.main.name\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# CRM Ingestor\nresource \"aws_lambda_function\" \"crm_ingestor\" {\n  function_name = \"${local.name_prefix}-crm-ingestor\"\n  role          = aws_iam_role.crm_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"ingestor.process_csv.handler\"\n  timeout       = 60\n  memory_size   = 512\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# Receipts Worker\nresource \"aws_lambda_function\" \"receipts_worker\" {\n  function_name = \"${local.name_prefix}-receipts-worker\"\n  role          = aws_iam_role.receipts_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"receipts.worker.handler\"\n  timeout       = 15\n  memory_size   = 256\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# Health check\nresource \"aws_lambda_function\" \"health\" {\n  function_name = \"${local.name_prefix}-health\"\n  role          = aws_iam_role.health_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"ops.health.handler\"\n  timeout       = 5\n  memory_size   = 128\n  filename      = data.archive_file.lambda_zip.output_path\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  environment {\n    variables = {\n      BUILD_SHA = \"dev\"\n    }\n  }\n\n  tags = local.common_tags\n}\n\n# ========== API Gateway Integrations ==========\n# POST /orders → orders_create\nresource \"aws_apigatewayv2_integration\" \"orders_create\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.orders_create.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"orders_create\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"POST /orders\"\n  target    = \"integrations/${aws_apigatewayv2_integration.orders_create.id}\"\n}\n\nresource \"aws_lambda_permission\" \"orders_create_invoke\" {\n  statement_id  = \"AllowAPIGatewayInvoke-orders-create\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.orders_create.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/orders\"\n}\n\n# GET /orders/{order_id} → orders_get\nresource \"aws_apigatewayv2_integration\" \"orders_get\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.orders_get.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"orders_get\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"GET /orders/{order_id}\"\n  target    = \"integrations/${aws_apigatewayv2_integration.orders_get.id}\"\n}\n\nresource \"aws_lambda_permission\" \"orders_get_invoke\" {\n  statement_id  = \"AllowAPIGatewayInvoke-orders-get\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.orders_get.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/orders/*\"\n}\n\n# POST /inventory/reserve → inventory_reserve\nresource \"aws_apigatewayv2_integration\" \"inventory_reserve\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.inventory_reserve.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"inventory_reserve\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"POST /inventory/reserve\"\n  target    = \"integrations/${aws_apigatewayv2_integration.inventory_reserve.id}\"\n}\n\nresource \"aws_lambda_permission\" \"inventory_reserve_invoke\" {\n  statement_id  = \"AllowAPIGatewayInvoke-inventory-reserve\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.inventory_reserve.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/inventory/reserve\"\n}\n\n# GET /health → health\nresource \"aws_apigatewayv2_integration\" \"health\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.health.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"health\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"GET /health\"\n  target    = \"integrations/${aws_apigatewayv2_integration.health.id}\"\n}\n\nresource \"aws_lambda_permission\" \"health_invoke\" {\n  statement_id  = \"AllowAPIGatewayInvoke-health\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.health.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/health\"\n}\n\n# ========== S3 → Lambda Trigger ==========\nresource \"aws_lambda_permission\" \"crm_s3_invoke\" {\n  statement_id  = \"AllowS3Invoke-crm-ingestor\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.crm_ingestor.function_name\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.crm_ingestion.arn\n}\n\nresource \"aws_s3_bucket_notification\" \"crm_notification\" {\n  bucket = aws_s3_bucket.crm_ingestion.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.crm_ingestor.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_suffix       = \".csv\"\n  }\n\n  depends_on = [aws_lambda_permission.crm_s3_invoke]\n}\n\n# ========== EventBridge Rules ==========\n# ReceiptGenerated → receipts_worker\nresource \"aws_cloudwatch_event_rule\" \"receipt_generated\" {\n  name           = \"${local.name_prefix}-receipt-generated\"\n  event_bus_name = aws_cloudwatch_event_bus.main.name\n  event_pattern = jsonencode({\n    source      = [\"app.orders\"]\n    detail-type = [\"ReceiptGenerated\"]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_cloudwatch_event_target\" \"receipt_worker\" {\n  rule           = aws_cloudwatch_event_rule.receipt_generated.name\n  event_bus_name = aws_cloudwatch_event_bus.main.name\n  arn            = aws_lambda_function.receipts_worker.arn\n}\n\nresource \"aws_lambda_permission\" \"receipt_events_invoke\" {\n  statement_id  = \"AllowEventBridgeInvoke-receipts\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.receipts_worker.function_name\n  principal     = \"events.amazonaws.com\"\n  source_arn    = aws_cloudwatch_event_rule.receipt_generated.arn\n}\n"
        },
        {
          "path": "infra/terraform/iam.tf",
          "content": "# infra/terraform/iam.tf\n# Least-privilege IAM roles and policies for each Lambda function.\n\n# ========== Orders Lambda Role ==========\nresource \"aws_iam_role\" \"orders_lambda\" {\n  name = \"${local.name_prefix}-orders-lambda-role\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"orders_lambda_logs\" {\n  role       = aws_iam_role.orders_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"orders_lambda_policy\" {\n  name = \"${local.name_prefix}-orders-lambda-policy\"\n  role = aws_iam_role.orders_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:GetItem\"\n        ]\n        Resource = aws_dynamodb_table.orders.arn\n      },\n      {\n        Effect = \"Allow\"\n        Action = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== Inventory Lambda Role ==========\nresource \"aws_iam_role\" \"inventory_lambda\" {\n  name = \"${local.name_prefix}-inventory-lambda-role\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"inventory_lambda_logs\" {\n  role       = aws_iam_role.inventory_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"inventory_lambda_policy\" {\n  name = \"${local.name_prefix}-inventory-lambda-policy\"\n  role = aws_iam_role.inventory_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:UpdateItem\"\n        ]\n        Resource = aws_dynamodb_table.inventory.arn\n      },\n      {\n        Effect = \"Allow\"\n        Action = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== CRM Ingestor Lambda Role ==========\nresource \"aws_iam_role\" \"crm_lambda\" {\n  name = \"${local.name_prefix}-crm-lambda-role\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"crm_lambda_logs\" {\n  role       = aws_iam_role.crm_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"crm_lambda_policy\" {\n  name = \"${local.name_prefix}-crm-lambda-policy\"\n  role = aws_iam_role.crm_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"s3:GetObject\"\n        ]\n        Resource = \"${aws_s3_bucket.crm_ingestion.arn}/*\"\n      },\n      {\n        Effect = \"Allow\"\n        Action = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== Receipts Worker Lambda Role ==========\nresource \"aws_iam_role\" \"receipts_lambda\" {\n  name = \"${local.name_prefix}-receipts-lambda-role\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"receipts_lambda_logs\" {\n  role       = aws_iam_role.receipts_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\n# ========== Health Lambda Role ==========\nresource \"aws_iam_role\" \"health_lambda\" {\n  name = \"${local.name_prefix}-health-lambda-role\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n  tags = local.common_tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"health_lambda_logs\" {\n  role       = aws_iam_role.health_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n"
        },
        {
          "path": "infra/terraform/outputs.tf",
          "content": "# infra/terraform/outputs.tf\n# Expose key resource identifiers for downstream use.\n\noutput \"api_endpoint\" {\n  description = \"HTTP API Gateway endpoint URL\"\n  value       = aws_apigatewayv2_api.http_api.api_endpoint\n}\n\noutput \"orders_table_name\" {\n  description = \"DynamoDB Orders table name\"\n  value       = aws_dynamodb_table.orders.name\n}\n\noutput \"inventory_table_name\" {\n  description = \"DynamoDB Inventory table name\"\n  value       = aws_dynamodb_table.inventory.name\n}\n\noutput \"event_bus_name\" {\n  description = \"EventBridge bus name\"\n  value       = aws_cloudwatch_event_bus.main.name\n}\n\noutput \"crm_bucket_name\" {\n  description = \"S3 bucket for CRM CSV ingestion\"\n  value       = aws_s3_bucket.crm_ingestion.bucket\n}\n\noutput \"orders_create_function_name\" {\n  description = \"Orders create Lambda function name\"\n  value       = aws_lambda_function.orders_create.function_name\n}\n\noutput \"orders_get_function_name\" {\n  description = \"Orders get Lambda function name\"\n  value       = aws_lambda_function.orders_get.function_name\n}\n\noutput \"inventory_reserve_function_name\" {\n  description = \"Inventory reserve Lambda function name\"\n  value       = aws_lambda_function.inventory_reserve.function_name\n}\n\noutput \"crm_ingestor_function_name\" {\n  description = \"CRM ingestor Lambda function name\"\n  value       = aws_lambda_function.crm_ingestor.function_name\n}\n\noutput \"receipts_worker_function_name\" {\n  description = \"Receipts worker Lambda function name\"\n  value       = aws_lambda_function.receipts_worker.function_name\n}\n\noutput \"health_function_name\" {\n  description = \"Health check Lambda function name\"\n  value       = aws_lambda_function.health.function_name\n}\n"
        }
      ]
    }
  },
  "ci": {
    "workflows": [
      {
        "path": ".github/workflows/ci.yml",
        "content": "name: CI/CD Pipeline\n\non:\n  pull_request:\n    branches: [main]\n  push:\n    branches: [main]\n\npermissions:\n  id-token: write\n  contents: read\n  pull-requests: write\n\nenv:\n  AWS_REGION: us-east-1\n  PYTHON_VERSION: '3.11'\n  TERRAFORM_VERSION: '1.7.0'\n\njobs:\n  lint:\n    name: Lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install flake8 black pylint\n\n      - name: Run flake8\n        run: flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics\n\n      - name: Run black (check only)\n        run: black --check src/\n\n  test:\n    name: Test\n    runs-on: ubuntu-latest\n    needs: lint\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest pytest-cov boto3 moto\n\n      - name: Run unit tests\n        run: |\n          pytest tests/ --cov=src --cov-report=xml --cov-report=term\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage.xml\n          flags: unittests\n\n  package:\n    name: Package Lambda\n    runs-on: ubuntu-latest\n    needs: test\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt -t src/\n\n      - name: Create deployment package\n        run: |\n          cd src\n          zip -r ../lambda_package.zip .\n          cd ..\n\n      - name: Upload artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: lambda-package\n          path: lambda_package.zip\n          retention-days: 7\n\n  terraform-validate:\n    name: Terraform Validate\n    runs-on: ubuntu-latest\n    needs: package\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TERRAFORM_VERSION }}\n\n      - name: Terraform Format Check\n        working-directory: infra/terraform\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Init\n        working-directory: infra/terraform\n        run: terraform init -backend=false\n\n      - name: Terraform Validate\n        working-directory: infra/terraform\n        run: terraform validate\n\n  terraform-plan:\n    name: Terraform Plan\n    runs-on: ubuntu-latest\n    needs: terraform-validate\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials (OIDC)\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TERRAFORM_VERSION }}\n\n      - name: Download Lambda package\n        uses: actions/download-artifact@v4\n        with:\n          name: lambda-package\n          path: infra/terraform/\n\n      - name: Terraform Init\n        working-directory: infra/terraform\n        run: |\n          terraform init \\\n            -backend-config=\"bucket=${{ secrets.TF_STATE_BUCKET }}\" \\\n            -backend-config=\"key=app/terraform.tfstate\" \\\n            -backend-config=\"region=${{ env.AWS_REGION }}\" \\\n            -backend-config=\"dynamodb_table=${{ secrets.TF_LOCK_TABLE }}\"\n\n      - name: Terraform Plan\n        id: plan\n        working-directory: infra/terraform\n        run: |\n          terraform plan \\\n            -var=\"project=${{ secrets.PROJECT_NAME }}\" \\\n            -var=\"env=staging\" \\\n            -var=\"region=${{ env.AWS_REGION }}\" \\\n            -out=tfplan\n\n      - name: Upload plan\n        uses: actions/upload-artifact@v4\n        with:\n          name: terraform-plan\n          path: infra/terraform/tfplan\n          retention-days: 7\n\n      - name: Comment PR with plan\n        if: github.event_name == 'pull_request'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const output = `#### Terraform Plan 📖\n            <details><summary>Show Plan</summary>\n\n            \\`\\`\\`\n            ${{ steps.plan.outputs.stdout }}\n            \\`\\`\\`\n\n            </details>\n\n            *Pusher: @${{ github.actor }}, Action: \\`${{ github.event_name }}\\`*`;\n\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: output\n            })\n\n  terraform-apply:\n    name: Terraform Apply (Staging)\n    runs-on: ubuntu-latest\n    needs: terraform-plan\n    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n    environment:\n      name: staging\n      url: ${{ steps.apply.outputs.api_endpoint }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials (OIDC)\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_DEPLOY_ROLE_ARN }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TERRAFORM_VERSION }}\n          terraform_wrapper: false\n\n      - name: Download Lambda package\n        uses: actions/download-artifact@v4\n        with:\n          name: lambda-package\n          path: infra/terraform/\n\n      - name: Download Terraform plan\n        uses: actions/download-artifact@v4\n        with:\n          name: terraform-plan\n          path: infra/terraform/\n\n      - name: Terraform Init\n        working-directory: infra/terraform\n        run: |\n          terraform init \\\n            -backend-config=\"bucket=${{ secrets.TF_STATE_BUCKET }}\" \\\n            -backend-config=\"key=app/terraform.tfstate\" \\\n            -backend-config=\"region=${{ env.AWS_REGION }}\" \\\n            -backend-config=\"dynamodb_table=${{ secrets.TF_LOCK_TABLE }}\"\n\n      - name: Terraform Apply\n        id: apply\n        working-directory: infra/terraform\n        run: |\n          terraform apply -auto-approve tfplan\n          echo \"api_endpoint=$(terraform output -raw api_endpoint)\" >> $GITHUB_OUTPUT\n\n      - name: Smoke Test\n        run: |\n          API_ENDPOINT=\"${{ steps.apply.outputs.api_endpoint }}\"\n          echo \"Testing health endpoint: ${API_ENDPOINT}/health\"\n          curl -f \"${API_ENDPOINT}/health\" || exit 1\n"
      }
    ]
  },
  "ops": {
    "env_vars": {
      "orders_create": {
        "ORDERS_TABLE": "DynamoDB table name for orders (auto-injected by Terraform)",
        "EVENT_BUS_NAME": "EventBridge bus name for emitting ReceiptGenerated events"
      },
      "orders_get": {
        "ORDERS_TABLE": "DynamoDB table name for orders (auto-injected by Terraform)"
      },
      "inventory_reserve": {
        "INVENTORY_TABLE": "DynamoDB table name for inventory and idempotency markers",
        "EVENT_BUS_NAME": "EventBridge bus name for emitting InventoryReserved events"
      },
      "crm_ingestor": {
        "EVENT_BUS_NAME": "EventBridge bus name for emitting CustomerUpserted events"
      },
      "receipts_worker": {
        "EVENT_BUS_NAME": "EventBridge bus name (informational; worker consumes events)"
      },
      "health": {
        "BUILD_SHA": "Git commit SHA for version tracking (set by CI)"
      }
    },
    "iam_policies": [
      {
        "name": "orders-lambda-policy",
        "policy_json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"dynamodb:PutItem\", \"dynamodb:GetItem\"],\n      \"Resource\": \"arn:aws:dynamodb:REGION:ACCOUNT:table/PROJECT-ENV-orders\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"events:PutEvents\",\n      \"Resource\": \"arn:aws:events:REGION:ACCOUNT:event-bus/PROJECT-ENV-bus\"\n    }\n  ]\n}"
      },
      {
        "name": "inventory-lambda-policy",
        "policy_json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"dynamodb:PutItem\", \"dynamodb:UpdateItem\"],\n      \"Resource\": \"arn:aws:dynamodb:REGION:ACCOUNT:table/PROJECT-ENV-inventory\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"events:PutEvents\",\n      \"Resource\": \"arn:aws:events:REGION:ACCOUNT:event-bus/PROJECT-ENV-bus\"\n    }\n  ]\n}"
      },
      {
        "name": "crm-lambda-policy",
        "policy_json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"s3:GetObject\",\n      \"Resource\": \"arn:aws:s3:::PROJECT-ENV-crm-ingestion/*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"events:PutEvents\",\n      \"Resource\": \"arn:aws:events:REGION:ACCOUNT:event-bus/PROJECT-ENV-bus\"\n    }\n  ]\n}"
      },
      {
        "name": "receipts-lambda-policy",
        "policy_json": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"logs:CreateLogGroup\",\n      \"Resource\": \"*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\"logs:CreateLogStream\", \"logs:PutLogEvents\"],\n      \"Resource\": \"arn:aws:logs:REGION:ACCOUNT:log-group:/aws/lambda/PROJECT-ENV-receipts-worker:*\"\n    }\n  ]\n}"
      }
    ],
    "alarms": [
      {
        "name": "OrdersCreateErrors",
        "description": "Alarm when orders-create Lambda error rate exceeds threshold (>5 errors in 5 minutes)"
      },
      {
        "name": "OrdersCreateThrottles",
        "description": "Alarm when orders-create Lambda is throttled"
      },
      {
        "name": "InventoryReserveErrors",
        "description": "Alarm when inventory-reserve Lambda error rate exceeds threshold"
      },
      {
        "name": "InventoryReserveThrottles",
        "description": "Alarm when inventory-reserve Lambda is throttled"
      },
      {
        "name": "CRMIngestorErrors",
        "description": "Alarm when CRM ingestor Lambda fails processing CSV files"
      },
      {
        "name": "API5xxErrors",
        "description": "Alarm when API Gateway returns 5xx errors (>10 in 5 minutes)"
      },
      {
        "name": "API4xxErrors",
        "description": "Monitor API Gateway 4xx errors for potential client issues"
      },
      {
        "name": "DynamoDBThrottles",
        "description": "Alarm when DynamoDB tables experience throttling (should be rare with on-demand)"
      },
      {
        "name": "EventBridgeFailedInvocations",
        "description": "Alarm when EventBridge fails to invoke Lambda targets"
      }
    ]
  },
  "readme.md": "# Serverless Application - Deployment Guide\n\n## Overview\nThis is a serverless application on AWS consisting of:\n- **Orders Service**: HTTP API for creating and retrieving orders\n- **Inventory Service**: HTTP API for reserving inventory with idempotency\n- **CRM Ingestor**: S3-triggered Lambda for processing CSV files\n- **Receipts Worker**: EventBridge-triggered Lambda for receipt generation\n- **Health Check**: Simple health endpoint\n\n## Architecture\n- **API Gateway (HTTP API)**: Routes HTTP requests to Lambda functions\n- **Lambda Functions**: Python 3.11 runtime for all business logic\n- **DynamoDB**: Orders and Inventory tables (on-demand billing)\n- **EventBridge**: Custom event bus for inter-service communication\n- **S3**: CRM CSV file ingestion bucket\n\n## Prerequisites\n- AWS Account with appropriate permissions\n- Terraform >= 1.7.0\n- Python 3.11\n- AWS CLI configured\n- GitHub repository with OIDC configured for AWS\n\n## Local Development\n\n### Setup\n```bash\n# Clone repository\ngit clone <repo-url>\ncd <repo-name>\n\n# Create virtual environment\npython3.11 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\npip install -r requirements-dev.txt\n```\n\n### Running Tests\n```bash\n# Run all tests with coverage\npytest tests/ --cov=src --cov-report=html\n\n# Run specific test file\npytest tests/test_orders.py -v\n\n# Run with mocked AWS services\npytest tests/ --mock-aws\n```\n\n### Local Lambda Testing\n```bash\n# Using AWS SAM CLI (if installed)\nsam local start-api\n\n# Or use Python directly\npython -c \"from src.orders.handlers import create_order; print(create_order({'body': '{\\\"total\\\": 100}'}, {}))\"\n```\n\n### Linting\n```bash\n# Format code\nblack src/\n\n# Check style\nflake8 src/\n\n# Type checking (if using mypy)\nmypy src/\n```\n\n## Deployment\n\n### Initial Setup\n\n1. **Create S3 bucket for Terraform state**:\n```bash\naws s3 mb s3://YOUR-PROJECT-staging-tfstate --region us-east-1\n```\n\n2. **Create DynamoDB table for state locking**:\n```bash\naws dynamodb create-table \\\n  --table-name YOUR-PROJECT-staging-tflock \\\n  --attribute-definitions AttributeName=LockID,AttributeType=S \\\n  --key-schema AttributeName=LockID,KeyType=HASH \\\n  --billing-mode PAY_PER_REQUEST \\\n  --region us-east-1\n```\n\n3. **Configure GitHub Secrets**:\n   - `AWS_DEPLOY_ROLE_ARN`: IAM role ARN for OIDC authentication\n   - `TF_STATE_BUCKET`: S3 bucket name for Terraform state\n   - `TF_LOCK_TABLE`: DynamoDB table name for state locking\n   - `PROJECT_NAME`: Your project name (e.g., \"serverless-app\")\n\n4. **Configure AWS OIDC Provider** (one-time setup):\n```bash\n# Follow AWS documentation to create OIDC provider for GitHub Actions\n# https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services\n```\n\n### Manual Deployment\n\n```bash\n# Navigate to Terraform directory\ncd infra/terraform\n\n# Initialize Terraform\nterraform init \\\n  -backend-config=\"bucket=YOUR-PROJECT-staging-tfstate\" \\\n  -backend-config=\"key=app/terraform.tfstate\" \\\n  -backend-config=\"region=us-east-1\" \\\n  -backend-config=\"dynamodb_table=YOUR-PROJECT-staging-tflock\"\n\n# Plan changes\nterraform plan \\\n  -var=\"project=YOUR-PROJECT\" \\\n  -var=\"env=staging\" \\\n  -var=\"region=us-east-1\"\n\n# Apply changes\nterraform apply \\\n  -var=\"project=YOUR-PROJECT\" \\\n  -var=\"env=staging\" \\\n  -var=\"region=us-east-1\"\n\n# Get outputs\nterraform output\n```\n\n### CI/CD Deployment\n\nDeployment is automated via GitHub Actions:\n\n- **Pull Requests**: Runs lint, test, and terraform plan (no apply)\n- **Main Branch**: Runs full pipeline including terraform apply to staging\n\n**Workflow**:\n1. Create feature branch\n2. Make changes and commit\n3. Open PR → CI runs validation and plan\n4. Review plan in PR comments\n5. Merge to main → Auto-deploy to staging\n\n## Testing Deployed Services\n\n### Get API Endpoint\n```bash\nAPI_ENDPOINT=$(terraform output -raw api_endpoint)\necho $API_ENDPOINT\n```\n\n### Health Check\n```bash\ncurl \"${API_ENDPOINT}/health\"\n```\n\n### Create Order\n```bash\ncurl -X POST \"${API_ENDPOINT}/orders\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"total\": 99.99}'\n```\n\n### Get Order\n```bash\nORDER_ID=\"<order-id-from-create>\"\ncurl \"${API_ENDPOINT}/orders/${ORDER_ID}\"\n```\n\n### Reserve Inventory\n```bash\ncurl -X POST \"${API_ENDPOINT}/inventory/reserve\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"sku\": \"WIDGET-001\", \"qty\": 5, \"request_id\": \"unique-req-123\"}'\n```\n\n### Upload CRM CSV\n```bash\nBUCKET_NAME=$(terraform output -raw crm_bucket_name)\necho \"customer_id,email,segment\n12345,test@example.com,premium\" > test.csv\naws s3 cp test.csv s3://${BUCKET_NAME}/test.csv\n```\n\n## Monitoring\n\n### CloudWatch Logs\n```bash\n# View logs for a specific function\naws logs tail /aws/lambda/YOUR-PROJECT-staging-orders-create --follow\n\n# Search logs\naws logs filter-log-events \\\n  --log-group-name /aws/lambda/YOUR-PROJECT-staging-orders-create \\\n  --filter-pattern \"ERROR\"\n```\n\n### CloudWatch Metrics\n- Navigate to CloudWatch Console\n- View Lambda metrics: Invocations, Errors, Duration, Throttles\n- View API Gateway metrics: Count, 4xx, 5xx, Latency\n- View DynamoDB metrics: ConsumedReadCapacity, ConsumedWriteCapacity\n\n### X-Ray Tracing (if enabled)\n```bash\n# View traces in X-Ray console\naws xray get-trace-summaries --start-time <timestamp> --end-time <timestamp>\n```\n\n## Rollback\n\n### Rollback via Terraform\n```bash\n# Checkout previous version\ngit checkout <previous-commit-sha>\n\n# Re-apply\ncd infra/terraform\nterraform apply\n```\n\n### Rollback Lambda Function Only\n```bash\n# List versions\naws lambda list-versions-by-function \\\n  --function-name YOUR-PROJECT-staging-orders-create\n\n# Update alias to previous version\naws lambda update-alias \\\n  --function-name YOUR-PROJECT-staging-orders-create \\\n  --name live \\\n  --function-version <previous-version>\n```\n\n## Troubleshooting\n\n### Lambda Errors\n1. Check CloudWatch Logs for stack traces\n2. Verify environment variables are set correctly\n3. Check IAM permissions\n4. Verify DynamoDB table exists and is accessible\n\n### API Gateway 5xx Errors\n1. Check Lambda function logs\n2. Verify Lambda has correct permissions to be invoked by API Gateway\n3. Check integration configuration\n\n### EventBridge Not Triggering\n1. Verify event pattern matches emitted events\n2. Check Lambda permissions for EventBridge invocation\n3. Review EventBridge rule metrics\n\n### S3 Trigger Not Working\n1. Verify S3 notification configuration\n2. Check Lambda permissions for S3 invocation\n3. Ensure file suffix matches filter (.csv)\n\n## Cleanup\n\n```bash\n# Destroy all resources\ncd infra/terraform\nterraform destroy \\\n  -var=\"project=YOUR-PROJECT\" \\\n  -var=\"env=staging\" \\\n  -var=\"region=us-east-1\"\n\n# Delete state bucket (after confirming no other environments use it)\naws s3 rb s3://YOUR-PROJECT-staging-tfstate --force\n\n# Delete lock table\naws dynamodb delete-table --table-name YOUR-PROJECT-staging-tflock\n```\n\n## Security Notes\n\n- **No secrets in code**: All secrets stored in AWS SSM Parameter Store or GitHub Secrets\n- **Least-privilege IAM**: Each Lambda has minimal required permissions\n- **OIDC Authentication**: CI/CD uses temporary credentials via OIDC\n- **Encrypted state**: Terraform state is encrypted at rest in S3\n- **Private APIs**: Consider adding API Gateway authorizers for production\n\n## Support\n\nFor issues or questions:\n1. Check CloudWatch Logs\n2. Review this README\n3. Consult Terraform documentation\n4. Open GitHub issue\n",
  "changelog.md": "# Changelog\n\n## Initial Stitch - 2024\n\n### Inferred Architecture\n\nBased on the BRD and provided source code, the following architecture was inferred and implemented:\n\n#### Services Identified\n1. **Orders Service**\n   - HTTP endpoints: `POST /orders` (create), `GET /orders/{order_id}` (retrieve)\n   - Storage: DynamoDB table with `order_id` as partition key\n   - Events: Emits `ReceiptGenerated` event to EventBridge after order creation\n   - Handlers: `src/orders/handlers.py::create_order`, `src/orders/handlers.py::get_order`\n\n2. **Inventory Service**\n   - HTTP endpoint: `POST /inventory/reserve`\n   - Storage: DynamoDB table with `sku` as partition key\n   - Idempotency: Uses `idem#{request_id}` items with 24-hour TTL\n   - Concurrency: Conditional expressions for atomic stock decrement\n   - Events: Emits `InventoryReserved` event on success\n   - Handler: `src/inventory/handlers.py::reserve`\n\n3. **CRM Ingestor**\n   - Trigger: S3 ObjectCreated events (*.csv files)\n   - Processing: Parses CSV rows, validates customer_id and email\n   - Events: Emits `CustomerUpserted` event per valid row\n   - Handler: `src/ingestor/process_csv.py::handler`\n\n4. **Receipts Worker**\n   - Trigger: EventBridge rule matching `app.orders` source and `ReceiptGenerated` detail-type\n   - Processing: No-op/logging (placeholder for future receipt generation)\n   - Handler: `src/receipts/worker.py::handler`\n\n5. **Health Check**\n   - HTTP endpoint: `GET /health`\n   - Returns status, build SHA, and timestamp\n   - Handler: `src/ops/health.py::handler`\n\n#### Infrastructure Components\n- **API Gateway**: HTTP API (v2) with CORS enabled\n- **Lambda Functions**: 6 functions (Python 3.11 runtime)\n- **DynamoDB**: 2 tables (orders, inventory) with on-demand billing\n- **EventBridge**: 1 custom event bus with 1 rule (ReceiptGenerated → receipts worker)\n- **S3**: 1 bucket for CRM CSV ingestion with Lambda trigger\n- **IAM**: Least-privilege roles per function, no wildcard permissions\n