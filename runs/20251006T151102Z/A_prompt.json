```json
{
  "bundle_manifest": [
    {
      "path": "infra/terraform/backend.tf",
      "purpose": "Terraform backend configuration (empty block; configured via CI -backend-config)",
      "note": "Backend values injected at runtime to avoid hardcoding"
    },
    {
      "path": "infra/terraform/providers.tf",
      "purpose": "AWS provider and required Terraform version",
      "note": "Includes project/env/region variables"
    },
    {
      "path": "infra/terraform/main.tf",
      "purpose": "Core infrastructure overlay: DynamoDB tables, EventBridge bus, S3 bucket, Lambda functions, HTTP API, event rules",
      "note": "Single overlay wiring all services per BRD"
    },
    {
      "path": "infra/terraform/iam.tf",
      "purpose": "IAM roles and policies for Lambda functions with least-privilege resource scoping",
      "note": "Scoped to specific tables, buckets, and event bus"
    },
    {
      "path": "infra/terraform/alarms.tf",
      "purpose": "CloudWatch alarms for Lambda errors, throttles, and API 5xx responses",
      "note": "Baseline observability per guardrails"
    },
    {
      "path": "infra/terraform/outputs.tf",
      "purpose": "Terraform outputs for API endpoint, table names, bus name, bucket name",
      "note": "Facilitates cross-stack references and CI validation"
    },
    {
      "path": "src/orders/handlers.py",
      "purpose": "Orders service handlers: create_order, get_order",
      "note": "Already provided; no changes needed"
    },
    {
      "path": "src/receipts/worker.py",
      "purpose": "Receipts worker (EventBridge consumer)",
      "note": "Already provided; no changes needed"
    },
    {
      "path": "src/ingestor/process_csv.py",
      "purpose": "CRM CSV ingestor (S3 trigger → EventBridge)",
      "note": "Already provided; no changes needed"
    },
    {
      "path": "src/inventory/handlers.py",
      "purpose": "Inventory reservation handler with idempotency",
      "note": "Already provided; no changes needed"
    },
    {
      "path": "src/ops/health.py",
      "purpose": "Health check endpoint",
      "note": "Already provided; no changes needed"
    },
    {
      "path": "tests/test_orders.py",
      "purpose": "Unit tests for orders handlers",
      "note": "Smoke tests for create_order and get_order"
    },
    {
      "path": "tests/test_inventory.py",
      "purpose": "Unit tests for inventory reserve handler",
      "note": "Tests idempotency and concurrency logic"
    },
    {
      "path": "tests/test_ingestor.py",
      "purpose": "Unit tests for CSV ingestor",
      "note": "Tests CSV parsing and event emission"
    },
    {
      "path": "tests/test_receipts.py",
      "purpose": "Unit tests for receipts worker",
      "note": "Smoke test for event handling"
    },
    {
      "path": "tests/test_health.py",
      "purpose": "Unit tests for health endpoint",
      "note": "Validates response structure"
    },
    {
      "path": ".github/workflows/ci.yml",
      "purpose": "GitHub Actions CI/CD pipeline with OIDC, lint, test, package, Terraform plan/apply",
      "note": "Stages: lint → test → package → terraform validate/plan; auto-apply to staging on main"
    },
    {
      "path": "requirements.txt",
      "purpose": "Python dependencies for Lambda functions",
      "note": "boto3 and other runtime dependencies"
    },
    {
      "path": "requirements-dev.txt",
      "purpose": "Development dependencies for testing and linting",
      "note": "pytest, moto, flake8, black"
    },
    {
      "path": "pytest.ini",
      "purpose": "Pytest configuration",
      "note": "Test discovery and output settings"
    },
    {
      "path": ".flake8",
      "purpose": "Flake8 linting configuration",
      "note": "Python code style enforcement"
    },
    {
      "path": "scripts/package.sh",
      "purpose": "Lambda packaging script for CI",
      "note": "Creates deployment zip with dependencies"
    },
    {
      "path": "readme.md",
      "purpose": "Project documentation and deployment instructions"
    },
    {
      "path": "changelog.md",
      "purpose": "Change log documenting initial stitch and design decisions"
    }
  ],
  "src": {
    "files": [
      {
        "path": "src/orders/handlers.py",
        "content": "# src/orders/handlers.py\nimport os, json, time, uuid, boto3\ndynamodb = boto3.resource(\"dynamodb\")\nevents   = boto3.client(\"events\")\n\nTABLE_NAME = os.getenv(\"ORDERS_TABLE\", \"\")\nBUS_NAME   = os.getenv(\"EVENT_BUS_NAME\", \"\")\n\ndef create_order(event, context):\n    body = json.loads(event.get(\"body\") or \"{}\")\n    if \"total\" not in body:\n        return {\"statusCode\":400,\"body\":json.dumps({\"error\":\"total required\"})}\n    order_id = str(uuid.uuid4())\n    item = {\n        \"order_id\": order_id,\n        \"status\": \"CREATED\",\n        \"total\": float(body.get(\"total\", 0.0)),\n        \"created_at\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n    }\n    dynamodb.Table(TABLE_NAME).put_item(Item=item)\n    if BUS_NAME:\n        events.put_events(Entries=[{\n            \"Source\":\"app.orders\",\n            \"DetailType\":\"ReceiptGenerated\",\n            \"Detail\":json.dumps({\"order_id\":order_id,\"total\":item[\"total\"]}),\n            \"EventBusName\": BUS_NAME\n        }])\n    return {\"statusCode\":201,\"body\":json.dumps({\"order_id\":order_id})}\n\ndef get_order(event, context):\n    order_id = (event.get(\"pathParameters\") or {}).get(\"order_id\")\n    if not order_id:\n        return {\"statusCode\":400,\"body\":\"order_id required\"}\n    res = dynamodb.Table(TABLE_NAME).get_item(Key={\"order_id\": order_id})\n    if \"Item\" not in res:\n        return {\"statusCode\":404,\"body\":\"Not found\"}\n    return {\"statusCode\":200,\"body\":json.dumps(res[\"Item\"])}\n"
      },
      {
        "path": "src/receipts/worker.py",
        "content": "# src/receipts/worker.py\nimport json, os\ndef handler(event, context):\n    # EventBridge batch; no-op mock for demo.\n    _ = os.getenv(\"EVENT_BUS_NAME\", \"\")\n    return {\"ok\": True, \"records\": len(event.get(\"Records\", [])) if isinstance(event.get(\"Records\"), list) else 0}\n"
      },
      {
        "path": "src/ingestor/process_csv.py",
        "content": "# src/ingestor/process_csv.py\nimport csv, os, json, boto3\ns3 = boto3.client(\"s3\")\nevents = boto3.client(\"events\")\n\nBUS_NAME = os.getenv(\"EVENT_BUS_NAME\", \"\")\n\ndef handler(event, context):\n    rec = (event.get(\"Records\") or [])[0][\"s3\"]\n    bucket = rec[\"bucket\"][\"name\"]; key = rec[\"object\"][\"key\"]\n    obj = s3.get_object(Bucket=bucket, Key=key)\n    body = obj[\"Body\"].read().decode()\n    count = 0\n    for row in csv.DictReader(body.splitlines()):\n        if not row.get(\"customer_id\") or not row.get(\"email\"):\n            continue\n        count += 1\n        if BUS_NAME:\n            events.put_events(Entries=[{\n                \"Source\":\"app.crm\",\n                \"DetailType\":\"CustomerUpserted\",\n                \"EventBusName\":BUS_NAME,\n                \"Detail\": json.dumps({\n                    \"customer_id\":row[\"customer_id\"],\n                    \"email\":row[\"email\"],\n                    \"segment\":row.get(\"segment\",\"\")\n                })\n            }])\n    return {\"ok\": True, \"emitted\": count}\n"
      },
      {
        "path": "src/inventory/handlers.py",
        "content": "# src/inventory/handlers.py\nimport os, json, time, boto3\nddb = boto3.client(\"dynamodb\")\nTABLE = os.getenv(\"INVENTORY_TABLE\", \"\")\nBUS   = os.getenv(\"EVENT_BUS_NAME\", \"\")\nevents = boto3.client(\"events\")\n\ndef reserve(event, context):\n    body = json.loads(event.get(\"body\") or \"{}\")\n    sku = body.get(\"sku\"); qty = int(body.get(\"qty\", 0)); req = body.get(\"request_id\")\n    if not sku or qty <= 0 or not req:\n        return {\"statusCode\":400,\"body\":json.dumps({\"error\":\"sku, qty>0, request_id required\"})}\n\n    # Idempotency marker: put if not exists\n    try:\n        ddb.put_item(\n          TableName=TABLE,\n          Item={\"sku\":{\"S\":f\"idem#{req}\"}, \"ttl\":{\"N\": str(int(time.time())+86400)}},\n          ConditionExpression=\"attribute_not_exists(sku)\"\n        )\n    except ddb.exceptions.ConditionalCheckFailedException:\n        return {\"statusCode\":200,\"body\":json.dumps({\"status\":\"duplicate\",\"request_id\":req})}\n\n    # Decrement stock with concurrency guard\n    try:\n        resp = ddb.update_item(\n          TableName=TABLE,\n          Key={\"sku\":{\"S\":sku}},\n          UpdateExpression=\"SET qty = qty - :q\",\n          ConditionExpression=\"qty >= :q\",\n          ExpressionAttributeValues={\":q\":{\"N\": str(qty)}},\n          ReturnValues=\"ALL_NEW\"\n        )\n    except ddb.exceptions.ConditionalCheckFailedException:\n        return {\"statusCode\":409,\"body\":json.dumps({\"error\":\"insufficient\"})}\n\n    remaining = int(resp[\"Attributes\"][\"qty\"][\"N\"])\n    if BUS:\n        events.put_events(Entries=[{\n          \"Source\":\"app.inventory\",\n          \"DetailType\":\"InventoryReserved\",\n          \"EventBusName\":BUS,\n          \"Detail\": json.dumps({\"sku\":sku,\"qty\":qty,\"remaining\":remaining,\"request_id\":req})\n        }])\n    return {\"statusCode\":200,\"body\":json.dumps({\"remaining\":remaining})}\n"
      },
      {
        "path": "src/ops/health.py",
        "content": "# src/ops/health.py\nimport json, os, time\ndef handler(event, context):\n    return {\n      \"statusCode\": 200,\n      \"body\": json.dumps({\n        \"status\":\"ok\",\n        \"sha\": os.getenv(\"BUILD_SHA\",\"dev\"),\n        \"time\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n      })\n    }\n"
      }
    ]
  },
  "infra": {
    "terraform": {
      "files": [
        {
          "path": "infra/terraform/backend.tf",
          "content": "# infra/terraform/backend.tf\n# Backend configuration intentionally empty.\n# CI will configure via: terraform init -backend-config=\"bucket=...\" -backend-config=\"key=...\" etc.\nterraform {\n  backend \"s3\" {}\n}\n"
        },
        {
          "path": "infra/terraform/providers.tf",
          "content": "# infra/terraform/providers.tf\nterraform {\n  required_version = \">= 1.7.0\"\n  required_providers {\n    aws = { source = \"hashicorp/aws\", version = \">= 5.0\" }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n  default_tags {\n    tags = merge(var.tags, {\n      Project     = var.project\n      Environment = var.env\n      ManagedBy   = \"Terraform\"\n    })\n  }\n}\n\nvariable \"region\"  { type = string }\nvariable \"project\" { type = string }\nvariable \"env\"     { type = string }\nvariable \"tags\"    { type = map(string) default = {} }\n"
        },
        {
          "path": "infra/terraform/main.tf",
          "content": "# infra/terraform/main.tf\n# Core infrastructure overlay: DynamoDB, EventBridge, S3, Lambda, HTTP API\n\nlocals {\n  prefix = \"${var.project}-${var.env}\"\n}\n\n# ========== DynamoDB Tables ==========\nresource \"aws_dynamodb_table\" \"orders\" {\n  name         = \"${local.prefix}-orders\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"order_id\"\n  attribute {\n    name = \"order_id\"\n    type = \"S\"\n  }\n}\n\nresource \"aws_dynamodb_table\" \"inventory\" {\n  name         = \"${local.prefix}-inventory\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"sku\"\n  attribute {\n    name = \"sku\"\n    type = \"S\"\n  }\n  ttl {\n    attribute_name = \"ttl\"\n    enabled        = true\n  }\n}\n\n# ========== EventBridge Bus ==========\nresource \"aws_cloudwatch_event_bus\" \"main\" {\n  name = \"${local.prefix}-bus\"\n}\n\n# ========== S3 Bucket for CRM CSV Ingestion ==========\nresource \"aws_s3_bucket\" \"crm_ingestion\" {\n  bucket        = \"${local.prefix}-crm-ingestion\"\n  force_destroy = true\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"crm_ingestion\" {\n  bucket                  = aws_s3_bucket.crm_ingestion.id\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\n# ========== Lambda Functions ==========\n# Orders: create_order\nresource \"aws_lambda_function\" \"orders_create\" {\n  function_name = \"${local.prefix}-orders-create\"\n  role          = aws_iam_role.orders_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"orders.handlers.create_order\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      ORDERS_TABLE   = aws_dynamodb_table.orders.name\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n}\n\n# Orders: get_order\nresource \"aws_lambda_function\" \"orders_get\" {\n  function_name = \"${local.prefix}-orders-get\"\n  role          = aws_iam_role.orders_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"orders.handlers.get_order\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      ORDERS_TABLE   = aws_dynamodb_table.orders.name\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n}\n\n# Receipts worker\nresource \"aws_lambda_function\" \"receipts_worker\" {\n  function_name = \"${local.prefix}-receipts-worker\"\n  role          = aws_iam_role.receipts_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"receipts.worker.handler\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n}\n\n# CRM CSV ingestor\nresource \"aws_lambda_function\" \"crm_ingestor\" {\n  function_name = \"${local.prefix}-crm-ingestor\"\n  role          = aws_iam_role.ingestor_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"ingestor.process_csv.handler\"\n  timeout       = 60\n  memory_size   = 512\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      EVENT_BUS_NAME = aws_cloudwatch_event_bus.main.name\n    }\n  }\n}\n\n# Inventory reserve\nresource \"aws_lambda_function\" \"inventory_reserve\" {\n  function_name = \"${local.prefix}-inventory-reserve\"\n  role          = aws_iam_role.inventory_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"inventory.handlers.reserve\"\n  timeout       = 15\n  memory_size   = 512\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      INVENTORY_TABLE = aws_dynamodb_table.inventory.name\n      EVENT_BUS_NAME  = aws_cloudwatch_event_bus.main.name\n    }\n  }\n}\n\n# Health check\nresource \"aws_lambda_function\" \"health\" {\n  function_name = \"${local.prefix}-health\"\n  role          = aws_iam_role.health_lambda.arn\n  runtime       = \"python3.11\"\n  handler       = \"ops.health.handler\"\n  timeout       = 10\n  memory_size   = 256\n  filename      = \"${path.module}/../../lambda_package.zip\"\n  source_code_hash = filebase64sha256(\"${path.module}/../../lambda_package.zip\")\n  environment {\n    variables = {\n      BUILD_SHA = \"staging\"\n    }\n  }\n}\n\n# ========== HTTP API Gateway ==========\nresource \"aws_apigatewayv2_api\" \"http_api\" {\n  name          = \"${local.prefix}-api\"\n  protocol_type = \"HTTP\"\n  cors_configuration {\n    allow_headers = [\"*\"]\n    allow_methods = [\"*\"]\n    allow_origins = [\"*\"]\n  }\n}\n\nresource \"aws_apigatewayv2_stage\" \"default\" {\n  api_id      = aws_apigatewayv2_api.http_api.id\n  name        = \"$default\"\n  auto_deploy = true\n}\n\n# Orders: POST /orders\nresource \"aws_apigatewayv2_integration\" \"orders_create\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.orders_create.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"orders_create\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"POST /orders\"\n  target    = \"integrations/${aws_apigatewayv2_integration.orders_create.id}\"\n}\n\nresource \"aws_lambda_permission\" \"orders_create_invoke\" {\n  statement_id  = \"AllowInvokeFromHttpApi-POST-orders\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.orders_create.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/orders\"\n}\n\n# Orders: GET /orders/{order_id}\nresource \"aws_apigatewayv2_integration\" \"orders_get\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.orders_get.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"orders_get\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"GET /orders/{order_id}\"\n  target    = \"integrations/${aws_apigatewayv2_integration.orders_get.id}\"\n}\n\nresource \"aws_lambda_permission\" \"orders_get_invoke\" {\n  statement_id  = \"AllowInvokeFromHttpApi-GET-orders\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.orders_get.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/orders/*\"\n}\n\n# Inventory: POST /inventory/reserve\nresource \"aws_apigatewayv2_integration\" \"inventory_reserve\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.inventory_reserve.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"inventory_reserve\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"POST /inventory/reserve\"\n  target    = \"integrations/${aws_apigatewayv2_integration.inventory_reserve.id}\"\n}\n\nresource \"aws_lambda_permission\" \"inventory_reserve_invoke\" {\n  statement_id  = \"AllowInvokeFromHttpApi-POST-inventory-reserve\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.inventory_reserve.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/inventory/reserve\"\n}\n\n# Health: GET /health\nresource \"aws_apigatewayv2_integration\" \"health\" {\n  api_id                 = aws_apigatewayv2_api.http_api.id\n  integration_type       = \"AWS_PROXY\"\n  integration_method     = \"POST\"\n  integration_uri        = aws_lambda_function.health.invoke_arn\n  payload_format_version = \"2.0\"\n}\n\nresource \"aws_apigatewayv2_route\" \"health\" {\n  api_id    = aws_apigatewayv2_api.http_api.id\n  route_key = \"GET /health\"\n  target    = \"integrations/${aws_apigatewayv2_integration.health.id}\"\n}\n\nresource \"aws_lambda_permission\" \"health_invoke\" {\n  statement_id  = \"AllowInvokeFromHttpApi-GET-health\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.health.function_name\n  principal     = \"apigateway.amazonaws.com\"\n  source_arn    = \"${aws_apigatewayv2_api.http_api.execution_arn}/*/*/health\"\n}\n\n# ========== S3 → Lambda Trigger ==========\nresource \"aws_lambda_permission\" \"s3_invoke_ingestor\" {\n  statement_id  = \"AllowInvokeFromS3\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.crm_ingestor.function_name\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.crm_ingestion.arn\n}\n\nresource \"aws_s3_bucket_notification\" \"crm_ingestion\" {\n  bucket = aws_s3_bucket.crm_ingestion.id\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.crm_ingestor.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_suffix       = \".csv\"\n  }\n  depends_on = [aws_lambda_permission.s3_invoke_ingestor]\n}\n\n# ========== EventBridge Rules ==========\n# ReceiptGenerated → receipts_worker\nresource \"aws_cloudwatch_event_rule\" \"receipt_generated\" {\n  name           = \"${local.prefix}-receipt-generated\"\n  event_bus_name = aws_cloudwatch_event_bus.main.name\n  event_pattern  = jsonencode({\n    source      = [\"app.orders\"]\n    detail-type = [\"ReceiptGenerated\"]\n  })\n}\n\nresource \"aws_cloudwatch_event_target\" \"receipt_generated\" {\n  rule           = aws_cloudwatch_event_rule.receipt_generated.name\n  event_bus_name = aws_cloudwatch_event_bus.main.name\n  arn            = aws_lambda_function.receipts_worker.arn\n}\n\nresource \"aws_lambda_permission\" \"receipt_generated_invoke\" {\n  statement_id  = \"AllowInvokeFromEventBridge-ReceiptGenerated\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.receipts_worker.function_name\n  principal     = \"events.amazonaws.com\"\n  source_arn    = aws_cloudwatch_event_rule.receipt_generated.arn\n}\n"
        },
        {
          "path": "infra/terraform/iam.tf",
          "content": "# infra/terraform/iam.tf\n# IAM roles and policies with least-privilege resource scoping\n\n# ========== Orders Lambda Role ==========\nresource \"aws_iam_role\" \"orders_lambda\" {\n  name = \"${local.prefix}-orders-lambda-exec\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"orders_lambda_logs\" {\n  role       = aws_iam_role.orders_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"orders_lambda_ddb\" {\n  name = \"orders-ddb-access\"\n  role = aws_iam_role.orders_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:GetItem\"\n        ]\n        Resource = aws_dynamodb_table.orders.arn\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy\" \"orders_lambda_events\" {\n  name = \"orders-events-access\"\n  role = aws_iam_role.orders_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect   = \"Allow\"\n        Action   = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== Receipts Lambda Role ==========\nresource \"aws_iam_role\" \"receipts_lambda\" {\n  name = \"${local.prefix}-receipts-lambda-exec\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"receipts_lambda_logs\" {\n  role       = aws_iam_role.receipts_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\n# ========== CRM Ingestor Lambda Role ==========\nresource \"aws_iam_role\" \"ingestor_lambda\" {\n  name = \"${local.prefix}-ingestor-lambda-exec\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ingestor_lambda_logs\" {\n  role       = aws_iam_role.ingestor_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"ingestor_lambda_s3\" {\n  name = \"ingestor-s3-access\"\n  role = aws_iam_role.ingestor_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect   = \"Allow\"\n        Action   = \"s3:GetObject\"\n        Resource = \"${aws_s3_bucket.crm_ingestion.arn}/*\"\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy\" \"ingestor_lambda_events\" {\n  name = \"ingestor-events-access\"\n  role = aws_iam_role.ingestor_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect   = \"Allow\"\n        Action   = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== Inventory Lambda Role ==========\nresource \"aws_iam_role\" \"inventory_lambda\" {\n  name = \"${local.prefix}-inventory-lambda-exec\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"inventory_lambda_logs\" {\n  role       = aws_iam_role.inventory_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role_policy\" \"inventory_lambda_ddb\" {\n  name = \"inventory-ddb-access\"\n  role = aws_iam_role.inventory_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:UpdateItem\"\n        ]\n        Resource = aws_dynamodb_table.inventory.arn\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy\" \"inventory_lambda_events\" {\n  name = \"inventory-events-access\"\n  role = aws_iam_role.inventory_lambda.id\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect   = \"Allow\"\n        Action   = \"events:PutEvents\"\n        Resource = aws_cloudwatch_event_bus.main.arn\n      }\n    ]\n  })\n}\n\n# ========== Health Lambda Role ==========\nresource \"aws_iam_role\" \"health_lambda\" {\n  name = \"${local.prefix}-health-lambda-exec\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect    = \"Allow\"\n      Principal = { Service = \"lambda.amazonaws.com\" }\n      Action    = \"sts:AssumeRole\"\n    }]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"health_lambda_logs\" {\n  role       = aws_iam_role.health_lambda.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n"
        },
        {
          "path": "infra/terraform/alarms.tf",
          "content": "# infra/terraform/alarms.tf\n# CloudWatch alarms for Lambda errors, throttles, and API 5xx responses\n\n# ========== Lambda Error Alarms ==========\nresource \"aws_cloudwatch_metric_alarm\" \"orders_create_errors\" {\n  alarm_name          = \"${local.prefix}-orders-create-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Errors\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"Orders create Lambda errors exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.orders_create.function_name\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"orders_get_errors\" {\n  alarm_name          = \"${local.prefix}-orders-get-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Errors\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"Orders get Lambda errors exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.orders_get.function_name\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"inventory_reserve_errors\" {\n  alarm_name          = \"${local.prefix}-inventory-reserve-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Errors\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"Inventory reserve Lambda errors exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.inventory_reserve.function_name\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"crm_ingestor_errors\" {\n  alarm_name          = \"${local.prefix}-crm-ingestor-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Errors\"\n  namespace           = \"AWS/Lambda\"\n  period              = 300\n  statistic           = \"Sum\"\n  threshold           = 3\n  alarm_description   = \"CRM ingestor Lambda errors exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.crm_ingestor.function_name\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"receipts_worker_errors\" {\n  alarm_name          = \"${local.prefix}-receipts-worker-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Errors\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"Receipts worker Lambda errors exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.receipts_worker.function_name\n  }\n}\n\n# ========== Lambda Throttle Alarms ==========\nresource \"aws_cloudwatch_metric_alarm\" \"orders_create_throttles\" {\n  alarm_name          = \"${local.prefix}-orders-create-throttles\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Throttles\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 3\n  alarm_description   = \"Orders create Lambda throttles exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.orders_create.function_name\n  }\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"inventory_reserve_throttles\" {\n  alarm_name          = \"${local.prefix}-inventory-reserve-throttles\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"Throttles\"\n  namespace           = \"AWS/Lambda\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 3\n  alarm_description   = \"Inventory reserve Lambda throttles exceed threshold\"\n  dimensions = {\n    FunctionName = aws_lambda_function.inventory_reserve.function_name\n  }\n}\n\n# ========== API Gateway 5xx Alarm ==========\nresource \"aws_cloudwatch_metric_alarm\" \"api_5xx\" {\n  alarm_name          = \"${local.prefix}-api-5xx-errors\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"5XXError\"\n  namespace           = \"AWS/ApiGateway\"\n  period              = 60\n  statistic           = \"Sum\"\n  threshold           = 5\n  alarm_description   = \"API Gateway 5xx errors exceed threshold\"\n  dimensions = {\n    ApiId = aws_apigatewayv2_api.http_api.id\n  }\n}\n"
        },
        {
          "path": "infra/terraform/outputs.tf",
          "content": "# infra/terraform/outputs.tf\n# Terraform outputs for API endpoint, table names, bus name, bucket name\n\noutput \"api_endpoint\" {\n  description = \"HTTP API Gateway endpoint\"\n  value       = aws_apigatewayv2_api.http_api.api_endpoint\n}\n\noutput \"orders_table_name\" {\n  description = \"Orders DynamoDB table name\"\n  value       = aws_dynamodb_table.orders.name\n}\n\noutput \"inventory_table_name\" {\n  description = \"Inventory DynamoDB table name\"\n  value       = aws_dynamodb_table.inventory.name\n}\n\noutput \"event_bus_name\" {\n  description = \"EventBridge bus name\"\n  value       = aws_cloudwatch_event_bus.main.name\n}\n\noutput \"crm_ingestion_bucket\" {\n  description = \"S3 bucket for CRM CSV ingestion\"\n  value       = aws_s3_bucket.crm_ingestion.bucket\n}\n\noutput \"lambda_functions\" {\n  description = \"Map of Lambda function names\"\n  value = {\n    orders_create      = aws_lambda_function.orders_create.function_name\n    orders_get         = aws_lambda_function.orders_get.function_name\n    receipts_worker    = aws_lambda_function.receipts_worker.function_name\n    crm_ingestor       = aws_lambda_function.crm_ingestor.function_name\n    inventory_reserve  = aws_lambda_function.inventory_reserve.function_name\n    health             = aws_lambda_function.health.function_name\n  }\n}\n"
        }
      ]
    }
  },
  "ci": {
    "workflows": [
      {
        "path": ".github/workflows/ci.yml",
        "content": "name: CI/CD Pipeline\n\non:\n  pull_request:\n    branches: [main]\n  push:\n    branches: [main]\n\nenv:\n  AWS_REGION: us-east-1\n  PROJECT: serverless-app\n  ENVIRONMENT: staging\n  TERRAFORM_VERSION: 1.7.0\n  PYTHON_VERSION: '3.11'\n\njobs:\n  lint:\n    name: Lint\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n      - name: Install dependencies\n        run: |\n          pip install -r requirements-dev.txt\n      - name: Run flake8\n        run: flake8 src/ tests/\n      - name: Run black check\n        run: black --check src/ tests/\n\n  test:\n    name: Test\n    runs-on: ubuntu-latest\n    needs: lint\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt -r requirements-dev.txt\n      - name: Run pytest\n        run: pytest tests/ -v --tb=short\n\n  package:\n    name: Package Lambda\n    runs-on: ubuntu-latest\n    needs: test\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n      - name: Create deployment package\n        run: |\n          bash scripts/package.sh\n      - name: Upload artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: lambda-package\n          path: lambda_package.zip\n          retention-days: 7\n\n  terraform-plan:\n    name: Terraform Plan\n    runs-on: ubuntu-latest\n    needs: package\n    permissions:\n      id-token: write\n      contents: read\n      pull-requests: write\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: lambda-package\n      - uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TERRAFORM_VERSION }}\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}\n          aws-region: ${{ env.AWS_REGION }}\n      - name: Terraform Init\n        working-directory: infra/terraform\n        run: |\n          terraform init \\\n            -backend-config=\"bucket=${{ secrets.TF_STATE_BUCKET }}\" \\\n            -backend-config=\"key=${{ env.PROJECT }}/${{ env.ENVIRONMENT }}/terraform.tfstate\" \\\n            -backend-config=\"region=${{ env.AWS_REGION }}\" \\\n            -backend-config=\"dynamodb_table=${{ secrets.TF_STATE_LOCK_TABLE }}\"\n      - name: Terraform Format Check\n        working-directory: infra/terraform\n        run: terraform fmt -check -recursive\n      - name: Terraform Validate\n        working-directory: infra/terraform\n        run: terraform validate\n      - name: Terraform Plan\n        working-directory: infra/terraform\n        run: |\n          terraform plan \\\n            -var=\"region=${{ env.AWS_REGION }}\" \\\n            -var=\"project=${{ env.PROJECT }}\" \\\n            -var=\"env=${{ env.ENVIRONMENT }}\" \\\n            -out=tfplan\n      - name: Upload plan\n        uses: actions/upload-artifact@v4\n        with:\n          name: terraform-plan\n          path: infra/terraform/tfplan\n          retention-days: 7\n\n  terraform-apply:\n    name: Terraform Apply (Staging)\n    runs-on: ubuntu-latest\n    needs: terraform-plan\n    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n    permissions:\n      id-token: write\n      contents: read\n    environment:\n      name: staging\n      url: ${{ steps.apply.outputs.api_endpoint }}\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/download-artifact@v4\n        with:\n          name: lambda-package\n      - uses: actions/download-artifact@v4\n        with:\n          name: terraform-plan\n          path: infra/terraform\n      - uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TERRAFORM_VERSION }}\n          terraform_wrapper: false\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}\n          aws-region: ${{ env.AWS_REGION }}\n      - name: Terraform Init\n        working-directory: infra/terraform\n        run: |\n          terraform init \\\n            -backend-config=\"bucket=${{ secrets.TF_STATE_BUCKET }}\" \\\n            -backend-config=\"key=${{ env.PROJECT }}/${{ env.ENVIRONMENT }}/terraform.tfstate\" \\\n            -backend-config=\"region=${{ env.AWS_REGION }}\" \\\n            -backend-config=\"dynamodb_table=${{ secrets.TF_STATE_LOCK_TABLE }}\"\n      - name: Terraform Apply\n        id: apply\n        working-directory: infra/terraform\n        run: |\n          terraform apply -auto-approve tfplan\n          echo \"api_endpoint=$(terraform output -raw api_endpoint)\" >> $GITHUB_OUTPUT\n      - name: Output deployment info\n        run: |\n          echo \"Deployment complete!\"\n          echo \"API Endpoint: ${{ steps.apply.outputs.api_endpoint }}\"\n"
      }
    ]
  },
  "ops": {
    "env_vars": {
      "orders_create": {
        "ORDERS_TABLE": "DynamoDB table name for orders",
        "EVENT_BUS_NAME": "EventBridge bus name for emitting events"
      },
      "orders_get": {
        "ORDERS_TABLE": "DynamoDB table name for orders",
        "EVENT_BUS_NAME": "EventBridge bus name (not used in get, but present)"
      },
      "receipts_worker": {
        "EVENT_BUS_NAME": "EventBridge bus name (informational)"
      },
      "crm_ingestor": {
        "EVENT_BUS_NAME": "EventBridge bus name for emitting CustomerUpserted events"
      },
      "inventory_reserve": {
        "INVENTORY_TABLE": "DynamoDB table name for inventory and idempotency markers",
        "EVENT_BUS_NAME": "EventBridge bus name for emitting InventoryReserved events"
      },
      "health": {
        "BUILD_SHA": "Build SHA or version identifier"
      }
    },
    "iam_policies": [
      {
        "name": "orders-ddb-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"dynamodb:PutItem\",\"dynamodb:GetItem\"],\"Resource\":\"<orders_table_arn>\"}]}"
      },
      {
        "name": "orders-events-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"events:PutEvents\",\"Resource\":\"<event_bus_arn>\"}]}"
      },
      {
        "name": "inventory-ddb-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"dynamodb:PutItem\",\"dynamodb:UpdateItem\"],\"Resource\":\"<inventory_table_arn>\"}]}"
      },
      {
        "name": "inventory-events-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"events:PutEvents\",\"Resource\":\"<event_bus_arn>\"}]}"
      },
      {
        "name": "ingestor-s3-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"s3:GetObject\",\"Resource\":\"<crm_bucket_arn>/*\"}]}"
      },
      {
        "name": "ingestor-events-access",
        "policy_json": "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"events:PutEvents\",\"Resource\":\"<event_bus_arn>\"}]}"
      }
    ],
    "alarms": [
      {
        "name": "orders-create-errors",
        "description": "Alarm when orders create Lambda errors exceed 5 in 1 minute"
      },
      {
        "name": "orders-get-errors",
        "description": "Alarm when orders get Lambda errors exceed 5 in 1 minute"
      },
      {
        "name": "inventory-reserve-errors",
        "description": "Alarm when inventory reserve Lambda errors exceed 5 in 1 minute"
      },
      {
        "name": "crm-ingestor-errors",
        "description": "Alarm when CRM ingestor Lambda errors exceed 3 in 5 minutes"
      },
      {
        "name": "receipts-worker-errors",
        "description": "Alarm when receipts worker Lambda errors exceed 5 in 1 minute"
      },
      {
        "name": "orders-create-throttles",
        "description": "Alarm when orders create Lambda throttles exceed 3 in 1 minute"
      },
      {
        "name": "inventory-reserve-throttles",
        "description": "Alarm when inventory reserve Lambda throttles exceed 3 in 1 minute"
      },
      {
        "name": "api-5xx-errors",
        "description": "Alarm when API Gateway 5xx errors exceed 5 in 1 minute"
      }
    ]
  },
  "readme.md": "# Serverless Backend Application\n\n## Overview\nThis is a serverless backend application deployed on AWS using Lambda, API Gateway, DynamoDB, EventBridge, and S3. The system supports:\n\n- **Orders Service**: Create and retrieve orders via HTTP API\n- **Receipts Worker**: Process order events asynchronously\n- **CRM Ingestion**: Parse CSV files from S3 and emit customer events\n- **Inventory Reservations**: Reserve inventory with idempotency guarantees\n- **Health Check**: Simple health endpoint\n\n## Architecture\n- **HTTP API**: API Gateway v2 with Lambda proxy integrations\n- **Functions**: Python 3.11 Lambda functions\n- **Storage**: DynamoDB (on-demand billing)\n- **Events**: EventBridge custom bus\n- **Ingestion**: S3 bucket with Lambda trigger\n- **Observability**: CloudWatch Logs, Metrics, and Alarms\n\n## Prerequisites\n- AWS Account with appropriate permissions\n- GitHub repository with OIDC configured for AWS\n- Terraform state S3 bucket and DynamoDB lock table\n- GitHub Secrets configured:\n  - `AWS_ROLE_ARN`: IAM role for OIDC authentication\n  - `TF_STATE_BUCKET`: S3 bucket for Terraform state\n  - `TF_STATE_LOCK_TABLE`: DynamoDB table for state locking\n\n## Local Development\n\n### Setup\n```bash\n# Install Python dependencies\npip install -r requirements.txt -r requirements-dev.txt\n\n# Run tests\npytest tests/ -v\n\n# Lint code\nflake8 src/ tests/\nblack src/ tests/\n```\n\n### Package Lambda\n```bash\nbash scripts/package.sh\n```\n\n## Deployment\n\n### CI/CD Pipeline\nThe GitHub Actions workflow automatically:\n1. Lints and tests code on every PR\n2. Packages Lambda functions\n3. Runs Terraform plan\n4. Applies to staging on merge to `main`\n\n### Manual Deployment\n```bash\ncd infra/terraform\n\n# Initialize with backend config\nterraform init \\\n  -backend-config=\"bucket=YOUR_STATE_BUCKET\" \\\n  -backend-config=\"key=serverless-app/staging/terraform.tfstate\" \\\n  -backend-config=\"region=us-east-1\" \\\n  -backend-config=\"dynamodb_table=YOUR_LOCK_TABLE\"\n\n# Plan\nterraform plan \\\n  -var=\"region=us-east-1\" \\\n  -var=\"project=serverless-app\" \\\n  -var=\"env=staging\"\n\n# Apply\nterraform apply\n```\n\n## API Endpoints\n\nAfter deployment, the API endpoint will be output. Example usage:\n\n### Health Check\n```bash\ncurl https://API_ENDPOINT/health\n```\n\n### Create Order\n```bash\ncurl -X POST https://API_ENDPOINT/orders \\\n  -H \"Content-Type